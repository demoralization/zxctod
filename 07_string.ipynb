{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/litw-win.txt', 'r') as file:\n",
    "    words = [s.split()[1] for s in file.read().split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'с величайшим усилием выбравшись из потока убегающих людей кутузов со свитой уменьшившейся вдвое поехал на звуки выстрелов русских орудий'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "for s in text.split(' '):\n",
    "    if s not in words:\n",
    "        good_wrd = words[0]\n",
    "        min_sz = edit_distance(s, good_wrd)\n",
    "        for word in words[1:]:\n",
    "            sz = edit_distance(s, word)\n",
    "            if sz < min_sz:\n",
    "                good_wrd = word\n",
    "                min_sz = sz\n",
    "        text = text.replace(s, good_wrd)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'счита слов из файл litw-win . txt и запиш их в список words . в зада предложен исправьт все опечатк , замен слов с опечатк на ближайш ( в смысл расстоян левенштейн ) к ним слов из списк words . счита , что в слов ест опечатк , есл дан слов не содерж в списк words .'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem import SnowballStemmer\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize\n",
    "\n",
    "snb_stemmer_ru = SnowballStemmer('russian')\n",
    "text = '''Считайте слова из файла litw-win.txt и запишите их в список words. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.'''\n",
    "\n",
    "tok = list(tokenize(text))\n",
    "w = re.compile('^[а-яА-ЯёЁ]*')\n",
    "' '.join([snb_stemmer_ru.stem(t.text) for t in tok if w.search(t.text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'считать слово из файл litw-win . txt и записать они в список words . в задать предложение исправить всё опечатка , заменить слово с опечатка на близкий ( в смысл расстояние левенштейн ) к они слово из список words . считать , что в слово есть опечатка , если данный слово не содержаться в список words .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymorphy3\n",
    "\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "pt = [morph.parse(t.text) for t in tok if w.search(t.text)] \n",
    "' '.join([w[0].normalized.word for w in pt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'preprocessed_descriptions'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/preprocessed_descriptions.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/unique_words.txt', 'r') as file:\n",
    "    words = file.read().split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layerof, paul = 6\n",
      "wanting, garland = 5\n",
      "chili, or = 5\n",
      "dimensions, tumblers = 8\n",
      "buy, servng = 6\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for _ in range(5):\n",
    "    pare = random.sample(words, 2)\n",
    "    print(f'{pare[0]}, {pare[1]} = {edit_distance(*pare)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amoretti',\n",
       " 'thickening',\n",
       " 'rose',\n",
       " 'kielbases',\n",
       " 'finsh',\n",
       " 'befroe',\n",
       " 'seaoned',\n",
       " 'tilt',\n",
       " 'ninths',\n",
       " 'tempered',\n",
       " 'fastest',\n",
       " 'ripeness',\n",
       " 'destem',\n",
       " 'saucepancook',\n",
       " 'beverage',\n",
       " 'suace',\n",
       " 'traingles',\n",
       " 'minuets',\n",
       " 'marbleized',\n",
       " 'uoy',\n",
       " 'arrabge',\n",
       " 'reusing',\n",
       " 'leche',\n",
       " 'softness',\n",
       " 'ultimate',\n",
       " 'coating',\n",
       " 'bratwursts',\n",
       " 'template',\n",
       " 'haze',\n",
       " 'proof',\n",
       " 'defatted',\n",
       " 'tomatillo',\n",
       " 'naam',\n",
       " 'exposing',\n",
       " 'proper',\n",
       " 'estimated',\n",
       " 'crem',\n",
       " 'enclose',\n",
       " 'spiciness',\n",
       " 'wiches',\n",
       " 'huey',\n",
       " 'ovent',\n",
       " 'lamingon',\n",
       " 'male',\n",
       " 'compressed',\n",
       " 'cruet',\n",
       " 'smoldering',\n",
       " 'applied',\n",
       " 'plums',\n",
       " 'cooling',\n",
       " 'hands',\n",
       " 'stiring',\n",
       " 'selected',\n",
       " 'wrinkly',\n",
       " 'adhering',\n",
       " 'elements',\n",
       " 'tenderly',\n",
       " 'angostura',\n",
       " 'catsup',\n",
       " 'carnitas',\n",
       " 'filberts',\n",
       " 'balloon',\n",
       " 'counting',\n",
       " 'mineral',\n",
       " 'lettuces',\n",
       " 'bunched',\n",
       " 'bore',\n",
       " 'snifter',\n",
       " 'association',\n",
       " 'lengths',\n",
       " 'pared',\n",
       " 'koechin',\n",
       " 'loins',\n",
       " 'sum',\n",
       " 'wet',\n",
       " 'rosemary',\n",
       " 'protected',\n",
       " 'whisky',\n",
       " 'worcesteshire',\n",
       " 'pinto',\n",
       " 'porchetta',\n",
       " 'pilaf',\n",
       " 'deseeded',\n",
       " 'lengthways',\n",
       " 'stabilise',\n",
       " 'all',\n",
       " 'scares',\n",
       " 'grainy',\n",
       " 'cheesy',\n",
       " 'bogg',\n",
       " 'altogether',\n",
       " 'smokes',\n",
       " 'brandied',\n",
       " 'paring',\n",
       " 'braided',\n",
       " 'hatch',\n",
       " 'siimmer',\n",
       " 'softed',\n",
       " 'reseving',\n",
       " 'saucepqn',\n",
       " 'restaurant',\n",
       " 'non',\n",
       " 'consisting',\n",
       " 'respray',\n",
       " 'smugly',\n",
       " 'unroll',\n",
       " 'dot',\n",
       " 'whitens',\n",
       " 'potsickers',\n",
       " 'clovers',\n",
       " 'eggwhites',\n",
       " 'gbad',\n",
       " 'fres',\n",
       " 'indoors',\n",
       " 'birds',\n",
       " 'cheeks',\n",
       " 'heady',\n",
       " 'hero',\n",
       " 'passionfruit',\n",
       " 'sprig',\n",
       " 'chickppeas',\n",
       " 'cycle',\n",
       " 'n',\n",
       " 'feedback',\n",
       " 'breast',\n",
       " 'mesclun',\n",
       " 'alonsdie',\n",
       " 'branston',\n",
       " 'he',\n",
       " 'frier',\n",
       " 'hearty',\n",
       " 'cheesecakein',\n",
       " 'pearly',\n",
       " 'jalepenos',\n",
       " 'omapodi',\n",
       " 'cloche',\n",
       " 'tuscan',\n",
       " 'mini',\n",
       " 'domes',\n",
       " 'sake',\n",
       " 'cashews',\n",
       " 'residual',\n",
       " 'remaining',\n",
       " 'rework',\n",
       " 'blanc',\n",
       " 'medley',\n",
       " 'waffles',\n",
       " 'furry',\n",
       " 'pourable',\n",
       " 'dredged',\n",
       " 'linger',\n",
       " 'score',\n",
       " 'build',\n",
       " 'girl',\n",
       " 'forman',\n",
       " 'salivary',\n",
       " 'jitomate',\n",
       " 'begins',\n",
       " 'puris',\n",
       " 'chappatis',\n",
       " 'administer',\n",
       " 'kirschwasser',\n",
       " 'spin',\n",
       " 'outstanding',\n",
       " 'gentleness',\n",
       " 'children',\n",
       " 'expresso',\n",
       " 'spinch',\n",
       " 'gridle',\n",
       " 'barberry',\n",
       " 'skillett',\n",
       " 'liime',\n",
       " 'bak',\n",
       " 'lidf',\n",
       " 'alexander',\n",
       " 'indivual',\n",
       " 'refried',\n",
       " 'gail',\n",
       " 'panch',\n",
       " 'sev',\n",
       " 'sheat',\n",
       " 'paneer',\n",
       " 'stirting',\n",
       " 'drop',\n",
       " 'mush',\n",
       " 'garbanza',\n",
       " 'pasteles',\n",
       " 'ready',\n",
       " 'ricota',\n",
       " 'heystopthatnow',\n",
       " 'accompanying',\n",
       " 'discolouring',\n",
       " 'variance',\n",
       " 'ypur',\n",
       " 'appeal',\n",
       " 'infants',\n",
       " 'hummus',\n",
       " 'maybe',\n",
       " 'ungrease',\n",
       " 'asked',\n",
       " 'picture',\n",
       " 'footed',\n",
       " 'river',\n",
       " 'kneading',\n",
       " 'sodi',\n",
       " 'oozing',\n",
       " 'mic',\n",
       " 'tendermouths',\n",
       " 'causes',\n",
       " 'vertical',\n",
       " 'centimeters',\n",
       " 'startin',\n",
       " 'stripe',\n",
       " 'presention',\n",
       " 'rennet',\n",
       " 'proportions',\n",
       " 'riccota',\n",
       " 'gobbling',\n",
       " 'passive',\n",
       " 'gether',\n",
       " 'hold',\n",
       " 'provent',\n",
       " 'bellpeppers',\n",
       " 'burpless',\n",
       " 'sephardic',\n",
       " 'regulate',\n",
       " 'wi',\n",
       " 'underlying',\n",
       " 'gun',\n",
       " 'romano',\n",
       " 'shortcake',\n",
       " 'accomodate',\n",
       " 'betweem',\n",
       " 'dinner',\n",
       " 'ea',\n",
       " 'diagonals',\n",
       " 'limeade',\n",
       " 'fix',\n",
       " 'r',\n",
       " 'tapping',\n",
       " 'foccacia',\n",
       " 'satisfaction',\n",
       " 'vegtable',\n",
       " 'bloomed',\n",
       " 'majoram',\n",
       " 'deliciousness',\n",
       " 'starts',\n",
       " 'tidy',\n",
       " 'slug',\n",
       " 'burrito',\n",
       " 'sirloin',\n",
       " 'liquified',\n",
       " 'flaps',\n",
       " 'stirrers',\n",
       " 'germ',\n",
       " 'detract',\n",
       " 'voice',\n",
       " 'mates',\n",
       " 'creak',\n",
       " 'gails',\n",
       " 'buns',\n",
       " 'slips',\n",
       " 'boconncini',\n",
       " 'avacados',\n",
       " 'morning',\n",
       " 'chardonnay',\n",
       " 'bucatini',\n",
       " 'thumped',\n",
       " 'epanema',\n",
       " 'decanter',\n",
       " 'crsut',\n",
       " 'herbs',\n",
       " 'adjustments',\n",
       " 'overtones',\n",
       " 'piped',\n",
       " 'crush',\n",
       " 'brownies',\n",
       " 'feeling',\n",
       " 'proceeding',\n",
       " 'electic',\n",
       " 'symbols',\n",
       " 'diabetisweet',\n",
       " 'liners',\n",
       " 'become',\n",
       " 'fleshed',\n",
       " 'normalcy',\n",
       " 'inverted',\n",
       " 'topcoat',\n",
       " 'swizzle',\n",
       " 'stern',\n",
       " 'throroughly',\n",
       " 'cardamons',\n",
       " 'fresno',\n",
       " 'whisk',\n",
       " 'enjoy',\n",
       " 'tightly',\n",
       " 'jalapeos',\n",
       " 'wh',\n",
       " 'prepre',\n",
       " 'seconeds',\n",
       " 'osso',\n",
       " 'comb',\n",
       " 'curb',\n",
       " 'appearing',\n",
       " 'damage',\n",
       " 'wieners',\n",
       " 'panckes',\n",
       " 'sure',\n",
       " 'overboard',\n",
       " 'entre',\n",
       " 'safari',\n",
       " 'skips',\n",
       " 'ihad',\n",
       " 'whiter',\n",
       " 'flavors',\n",
       " 'plink',\n",
       " 'rosti',\n",
       " 'dose',\n",
       " 'doneness',\n",
       " 'toned',\n",
       " 'snowballs',\n",
       " 'liquer',\n",
       " 'thirty',\n",
       " 'quart',\n",
       " 'candiquik',\n",
       " 'houston',\n",
       " 'wildly',\n",
       " 'emulsify',\n",
       " 'yellowish',\n",
       " 'candies',\n",
       " 'odor',\n",
       " 'jammy',\n",
       " 'alice',\n",
       " 'untie',\n",
       " 'western',\n",
       " 'asparagas',\n",
       " 'accidentally',\n",
       " 'sick',\n",
       " 'servingd',\n",
       " 'theirs',\n",
       " 'screening',\n",
       " 'lb',\n",
       " 'arepas',\n",
       " 'assortment',\n",
       " 'siew',\n",
       " 'whistle',\n",
       " 'handfulls',\n",
       " 'fibrous',\n",
       " 'borlotti',\n",
       " 'oiling',\n",
       " 'group',\n",
       " 'improper',\n",
       " 'shakes',\n",
       " 'sweetcorn',\n",
       " 'gratinate',\n",
       " 'speeds',\n",
       " 'coat',\n",
       " 'marlin',\n",
       " 'saucers',\n",
       " 'butterhorns',\n",
       " 'forcing',\n",
       " 'tostadas',\n",
       " 'consomm',\n",
       " 'taut',\n",
       " 'mortadella',\n",
       " 'pale',\n",
       " 'bluefish',\n",
       " 'splenda',\n",
       " 'formimg',\n",
       " 'doughboys',\n",
       " 'martini',\n",
       " 'subject',\n",
       " 'party',\n",
       " 'hish',\n",
       " 'scorch',\n",
       " 'damn',\n",
       " 'pharmacy',\n",
       " 'anymore',\n",
       " 'ten',\n",
       " 'backing',\n",
       " 'filters',\n",
       " 'evoo',\n",
       " 'smmothie',\n",
       " 'mashmallow',\n",
       " 'unseasoned',\n",
       " 'markings',\n",
       " 'midnight',\n",
       " 'protector',\n",
       " 'hand',\n",
       " 'lumping',\n",
       " 'lemongrass',\n",
       " 'untild',\n",
       " 'brilliant',\n",
       " 'dealt',\n",
       " 'seas',\n",
       " 'flamb',\n",
       " 'integrated',\n",
       " 'drinks',\n",
       " 'restore',\n",
       " 'starches',\n",
       " 'themometer',\n",
       " 'zuccini',\n",
       " 'gathered',\n",
       " 'fact',\n",
       " 'loan',\n",
       " 'german',\n",
       " 'fake',\n",
       " 'reduct',\n",
       " 'streusel',\n",
       " 'fennel',\n",
       " 'orange',\n",
       " 'coins',\n",
       " 'dumb',\n",
       " 'distance',\n",
       " 'preparingthe',\n",
       " 'roni',\n",
       " 'tenderise',\n",
       " 'detest',\n",
       " 'mmixture',\n",
       " 'cinch',\n",
       " 'celebrate',\n",
       " 'distilled',\n",
       " 'placement',\n",
       " 'ended',\n",
       " 'insdie',\n",
       " 'pastry',\n",
       " 'pilot',\n",
       " 'george',\n",
       " 'sharpened',\n",
       " 'prunes',\n",
       " 'gobs',\n",
       " 'donair',\n",
       " 'drgrees',\n",
       " 'bouillon',\n",
       " 'unmold',\n",
       " 'sophisticated',\n",
       " 'litres',\n",
       " 'bugles',\n",
       " 'temp',\n",
       " 'poato',\n",
       " 'hotpot',\n",
       " 'pitcherand',\n",
       " 'coco',\n",
       " 'overcook',\n",
       " 'cartilage',\n",
       " 'squash',\n",
       " 'chance',\n",
       " 'completly',\n",
       " 'hamballs',\n",
       " 'carefulthe',\n",
       " 'sparkpeople',\n",
       " 'oversalt',\n",
       " 'olek',\n",
       " 'mediom',\n",
       " 'constarch',\n",
       " 'dedicated',\n",
       " 'hallow',\n",
       " 'el',\n",
       " 'mock',\n",
       " 'alligators',\n",
       " 'matching',\n",
       " 'btu',\n",
       " 'rubbery',\n",
       " 'bleed',\n",
       " 'cracked',\n",
       " 'ducth',\n",
       " 'lashings',\n",
       " 'careful',\n",
       " 'react',\n",
       " 'piping',\n",
       " 'rinserice',\n",
       " 'barbari',\n",
       " 'cuppa',\n",
       " 'and',\n",
       " 'pyramid',\n",
       " 'fed',\n",
       " 'nugget',\n",
       " 'his',\n",
       " 'marbled',\n",
       " 'hea',\n",
       " 'org',\n",
       " 'marjority',\n",
       " 'replicate',\n",
       " 'indicating',\n",
       " 'condensation',\n",
       " 'tumbler',\n",
       " 'domino',\n",
       " 'union',\n",
       " 'potassium',\n",
       " 'pannacotta',\n",
       " 'crumbley',\n",
       " 'alfoil',\n",
       " 'approximly',\n",
       " 'sprite',\n",
       " 'blade',\n",
       " 'sperate',\n",
       " 'macerate',\n",
       " 'pan',\n",
       " 'meadium',\n",
       " 'ahh',\n",
       " 'moans',\n",
       " 'sauteed',\n",
       " 'somewhat',\n",
       " 'ingrediens',\n",
       " 'fixings',\n",
       " 'equipment',\n",
       " 'liquor',\n",
       " 'happens',\n",
       " 'rest',\n",
       " 'brooks',\n",
       " 'engine',\n",
       " 'prosesser',\n",
       " 'shrivel',\n",
       " 'anyones',\n",
       " 'freezing',\n",
       " 'roasted',\n",
       " 'fallowed',\n",
       " 'bratwurst',\n",
       " 'evelyn',\n",
       " 'decadent',\n",
       " 'sheild',\n",
       " 'raspberry',\n",
       " 'steviva',\n",
       " 'disapear',\n",
       " 'flute',\n",
       " 'solidified',\n",
       " 'proscuitto',\n",
       " 'wigging',\n",
       " 'individual',\n",
       " 'airy',\n",
       " 'blob',\n",
       " 'fir',\n",
       " 'lights',\n",
       " 'reflour',\n",
       " 'circular',\n",
       " 'meltled',\n",
       " 'worked',\n",
       " 'beginning',\n",
       " 'smucker',\n",
       " 'ropa',\n",
       " 'slotted',\n",
       " 'smuckers',\n",
       " 'salad',\n",
       " 'grated',\n",
       " 'dipped',\n",
       " 'poppyseeds',\n",
       " 'mutton',\n",
       " 'ingredsients',\n",
       " 'margrin',\n",
       " 'doug',\n",
       " 'container',\n",
       " 'fresche',\n",
       " 'pounders',\n",
       " 'gladware',\n",
       " 'biscut',\n",
       " 'ingrdients',\n",
       " 'country',\n",
       " 'fowl',\n",
       " 'spruce',\n",
       " 'many',\n",
       " 'info',\n",
       " 'adjacent',\n",
       " 'modifications',\n",
       " 'julio',\n",
       " 'cremed',\n",
       " 'undissolved',\n",
       " 'colored',\n",
       " 'hint',\n",
       " 'farmhouse',\n",
       " 'addicting',\n",
       " 'categories',\n",
       " 'shoestring',\n",
       " 'guinoa',\n",
       " 'georgia',\n",
       " 'chick',\n",
       " 'terrine',\n",
       " 'riace',\n",
       " 'clumpy',\n",
       " 'bel',\n",
       " 'hunts',\n",
       " 'whiped',\n",
       " 'origanum',\n",
       " 'tv',\n",
       " 'accoring',\n",
       " 'granular',\n",
       " 'bowties',\n",
       " 'wrap',\n",
       " 'wok',\n",
       " 'loafpan',\n",
       " 'mosels',\n",
       " 'bas',\n",
       " 'intestinal',\n",
       " 'chil',\n",
       " 'manicotti',\n",
       " 'marble',\n",
       " 'smoothed',\n",
       " 'would',\n",
       " 'seal',\n",
       " 'june',\n",
       " 'distrubuted',\n",
       " 'grasp',\n",
       " 'whizz',\n",
       " 'zone',\n",
       " 'cord',\n",
       " 'minimum',\n",
       " 'overnight',\n",
       " 'teaspoon',\n",
       " 'gemelli',\n",
       " 'luntil',\n",
       " 'appetizers',\n",
       " 'manouri',\n",
       " 'main',\n",
       " 'yolks',\n",
       " 'lastly',\n",
       " 'bundt',\n",
       " 'occasionlly',\n",
       " 'pitch',\n",
       " 'cools',\n",
       " 'candle',\n",
       " 'simpler',\n",
       " 'foley',\n",
       " 'capsfull',\n",
       " 'responsibly',\n",
       " 'coer',\n",
       " 'vincotto',\n",
       " 'lip',\n",
       " 'satiny',\n",
       " 'coffees',\n",
       " 'towles',\n",
       " 'inbetween',\n",
       " 'sooner',\n",
       " 'shroom',\n",
       " 'coddled',\n",
       " 'grillt',\n",
       " 'seaon',\n",
       " 'reseal',\n",
       " 'lekvar',\n",
       " 'tuperware',\n",
       " 'chicken',\n",
       " 'crispy',\n",
       " 'standing',\n",
       " 'compounds',\n",
       " 'kababs',\n",
       " 'concerning',\n",
       " 'wool',\n",
       " 'bisquits',\n",
       " 'tent',\n",
       " 'solids',\n",
       " 'sheetpan',\n",
       " 'sixth',\n",
       " 'rasins',\n",
       " 'years',\n",
       " 'cheesecakes',\n",
       " 'cannister',\n",
       " 'watcher',\n",
       " 'lychees',\n",
       " 'togethether',\n",
       " 'strainer',\n",
       " 'tapioca',\n",
       " 'toothpics',\n",
       " 'chicory',\n",
       " 'pace',\n",
       " 'flag',\n",
       " 'classy',\n",
       " 'summertime',\n",
       " 'saki',\n",
       " 'ken',\n",
       " 'thorny',\n",
       " 'yep',\n",
       " 'lean',\n",
       " 'halibut',\n",
       " 'skor',\n",
       " 'prepare',\n",
       " 'block',\n",
       " 'happened',\n",
       " 'vidalia',\n",
       " 'justa',\n",
       " 'tablespoonsful',\n",
       " 'blot',\n",
       " 'finley',\n",
       " 'scrapings',\n",
       " 'bay',\n",
       " 'aparagus',\n",
       " 'sorts',\n",
       " 'additional',\n",
       " 'blessing',\n",
       " 'boneless',\n",
       " 'ensures',\n",
       " 'tp',\n",
       " 'hotness',\n",
       " 'applebee',\n",
       " 'dirt',\n",
       " 'balls',\n",
       " 'tightfitting',\n",
       " 'tidbits',\n",
       " 'compartment',\n",
       " 'keys',\n",
       " 'relaxed',\n",
       " 'recreate',\n",
       " 'flavorings',\n",
       " 'appendages',\n",
       " 'teethmarks',\n",
       " 'cards',\n",
       " 'pare',\n",
       " 'blacken',\n",
       " 'scooped',\n",
       " 'considtency',\n",
       " 'simemr',\n",
       " 'bulb',\n",
       " 'around',\n",
       " 'autumn',\n",
       " 'ocean',\n",
       " 'lukewarm',\n",
       " 'pears',\n",
       " 'turbinado',\n",
       " 'tennis',\n",
       " 'ridge',\n",
       " 'faithful',\n",
       " 'beauty',\n",
       " 'technically',\n",
       " 'kleftiko',\n",
       " 'enhancer',\n",
       " 'zapraka',\n",
       " 'displacing',\n",
       " 'jalapenoes',\n",
       " 'aniseeds',\n",
       " 'win',\n",
       " 'gochujang',\n",
       " 'savoy',\n",
       " 'xylitol',\n",
       " 'silverskin',\n",
       " 'vine',\n",
       " 'bridget',\n",
       " 'fosting',\n",
       " 'mood',\n",
       " 'chickpease',\n",
       " 'don',\n",
       " 'thinnest',\n",
       " 'wanter',\n",
       " 'dissuaded',\n",
       " 'pacakge',\n",
       " 'thenmushrooms',\n",
       " 'liquefies',\n",
       " 'bi',\n",
       " 'diemersdal',\n",
       " 'appox',\n",
       " 'ito',\n",
       " 'pulsed',\n",
       " 'overflow',\n",
       " 'minuted',\n",
       " 'cupcakes',\n",
       " 'excesssively',\n",
       " 'trussing',\n",
       " 'bollio',\n",
       " 'decent',\n",
       " 'toddy',\n",
       " 'minted',\n",
       " 'grappa',\n",
       " 'stemmed',\n",
       " 'slowcooker',\n",
       " 'batter',\n",
       " 'gorgonzola',\n",
       " 'sucked',\n",
       " 'barrel',\n",
       " 'intolerableprobably',\n",
       " 'galzed',\n",
       " 'subtle',\n",
       " 'inspect',\n",
       " 'date',\n",
       " 'accumulating',\n",
       " 'wobble',\n",
       " 'bannock',\n",
       " 'jacobs',\n",
       " 'indirect',\n",
       " 'tomatoand',\n",
       " 'critique',\n",
       " 'rhum',\n",
       " 'misted',\n",
       " 'matchsticks',\n",
       " 'knobby',\n",
       " 'tucker',\n",
       " 'inthe',\n",
       " 'visual',\n",
       " 'jar',\n",
       " 'varying',\n",
       " 'rosmary',\n",
       " 'needs',\n",
       " 'pimento',\n",
       " 'jarred',\n",
       " 'dices',\n",
       " 'prepared',\n",
       " 'occ',\n",
       " 'unmolded',\n",
       " 'destination',\n",
       " 'agitation',\n",
       " 'minutees',\n",
       " 'processor',\n",
       " 'smallslits',\n",
       " 'ham',\n",
       " 'lays',\n",
       " 'glow',\n",
       " 'evap',\n",
       " 'staying',\n",
       " 'headroom',\n",
       " 'milligrams',\n",
       " 'rabe',\n",
       " 'nasturtiums',\n",
       " 'prolonged',\n",
       " 'serious',\n",
       " 'sand',\n",
       " 'loaves',\n",
       " 'cushion',\n",
       " 'spahetti',\n",
       " 'stirr',\n",
       " 'indention',\n",
       " 'withstand',\n",
       " 'cones',\n",
       " 'rewarm',\n",
       " 'churros',\n",
       " 'lumps',\n",
       " 'tacheen',\n",
       " 'depaz',\n",
       " 'capiscum',\n",
       " 'capped',\n",
       " 'spred',\n",
       " 'class',\n",
       " 'refrigeratoruntil',\n",
       " 'robust',\n",
       " 'cavity',\n",
       " 'morels',\n",
       " 'definition',\n",
       " 'disolved',\n",
       " 'grave',\n",
       " 'rhind',\n",
       " 'harden',\n",
       " 'strew',\n",
       " 'divides',\n",
       " 'shallot',\n",
       " 'fingersto',\n",
       " 'llowing',\n",
       " 'stumps',\n",
       " 'kingsford',\n",
       " 'minsutes',\n",
       " 'directs',\n",
       " 'hgh',\n",
       " 'any',\n",
       " 'tastebuds',\n",
       " 'watts',\n",
       " 'alumium',\n",
       " 'oblongs',\n",
       " 'exit',\n",
       " 'almunim',\n",
       " 'betcha',\n",
       " 'orcestershire',\n",
       " 'galette',\n",
       " 'essences',\n",
       " 'lutfisk',\n",
       " 'chalky',\n",
       " 'switch',\n",
       " 'slathered',\n",
       " 'declared',\n",
       " 'stady',\n",
       " 'waldrof',\n",
       " 'pelati',\n",
       " 'summer',\n",
       " 'footballs',\n",
       " 'slick',\n",
       " 'seltzer',\n",
       " 'rarebit',\n",
       " 'liqeuors',\n",
       " 'mallet',\n",
       " 'ps',\n",
       " 'bruises',\n",
       " 'wave',\n",
       " 'cals',\n",
       " 'approximately',\n",
       " 'splah',\n",
       " 'shaoxing',\n",
       " 'watched',\n",
       " 'worchestershire',\n",
       " 'motzarella',\n",
       " 'ow',\n",
       " 'slight',\n",
       " 'andoullie',\n",
       " 'stream',\n",
       " 'bison',\n",
       " 'craisin',\n",
       " 'ckened',\n",
       " 'lattice',\n",
       " 'splits',\n",
       " 'mandarines',\n",
       " 'axis',\n",
       " 'converted',\n",
       " 'colorful',\n",
       " 'ice',\n",
       " 'gallo',\n",
       " 'flowerets',\n",
       " 'ingredient',\n",
       " 'blened',\n",
       " 'hangers',\n",
       " 'rolo',\n",
       " 'star',\n",
       " 'gelato',\n",
       " 'tapas',\n",
       " 'x',\n",
       " 'insulates',\n",
       " 'within',\n",
       " 'flatbreads',\n",
       " 'asafetida',\n",
       " 'sheape',\n",
       " 'girlfriends',\n",
       " 'dent',\n",
       " 'shouldnt',\n",
       " 'couscous',\n",
       " 'aforementioned',\n",
       " 'cachaca',\n",
       " 'hardens',\n",
       " 'gluey',\n",
       " 'chill',\n",
       " 'yumminess',\n",
       " 'level',\n",
       " 'feel',\n",
       " 'dripping',\n",
       " 'communal',\n",
       " 'particles',\n",
       " 'tired',\n",
       " 'exceed',\n",
       " 'chcken',\n",
       " 'unrolling',\n",
       " 'seasonall',\n",
       " 'crispest',\n",
       " 'spluttering',\n",
       " 'lived',\n",
       " 'deveine',\n",
       " 'hottest',\n",
       " 'cookings',\n",
       " 'ruined',\n",
       " 'drumettes',\n",
       " 'blanching',\n",
       " 'sevillian',\n",
       " 'shucks',\n",
       " 'alarming',\n",
       " 'lblended',\n",
       " 'sticking',\n",
       " 'insalada',\n",
       " 'salute',\n",
       " 'cost',\n",
       " 'melded',\n",
       " 'prinkle',\n",
       " 'amout',\n",
       " 'bar',\n",
       " 'submerging',\n",
       " 'superfine',\n",
       " 'pepsi',\n",
       " 'thing',\n",
       " 'able',\n",
       " 'velvetta',\n",
       " 'bb',\n",
       " 'powderd',\n",
       " 'babies',\n",
       " 'cultural',\n",
       " 'palette',\n",
       " 'crowns',\n",
       " 'vitamins',\n",
       " 'hoagie',\n",
       " 'gels',\n",
       " 'american',\n",
       " 'dlip',\n",
       " 'packets',\n",
       " 'amonds',\n",
       " 'watch',\n",
       " 'lockjaw',\n",
       " 'stopper',\n",
       " 'lentils',\n",
       " 'pine',\n",
       " 'curled',\n",
       " 'besides',\n",
       " 'ryes',\n",
       " 'knee',\n",
       " 'caloric',\n",
       " 'cooktop',\n",
       " 'vomiting',\n",
       " 'rareness',\n",
       " 'picada',\n",
       " 'tuns',\n",
       " 'peasant',\n",
       " 'efficiently',\n",
       " 'sautgarlic',\n",
       " 'pice',\n",
       " 'jerk',\n",
       " 'helpful',\n",
       " 'damper',\n",
       " 'tortas',\n",
       " 'crystallize',\n",
       " 'smokie',\n",
       " 'kneed',\n",
       " 'mixtur',\n",
       " 'juniper',\n",
       " 'lighltly',\n",
       " 'aobut',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amoretti': 1, 'thickening': 9, 'rose': 7, 'shaking': 7}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unique_words():\n",
    "    with open('data/unique_words.txt', 'r') as file:\n",
    "        return file.read().split(' ')\n",
    "\n",
    "def back_wrds(main_word, k):\n",
    "    closest = {}\n",
    "    words = get_unique_words()\n",
    "    for word in words:\n",
    "        if word == '':\n",
    "            continue\n",
    "        distance = edit_distance(main_word, word)\n",
    "        if len(closest) < k:\n",
    "            closest[word] = distance\n",
    "        elif max(closest.values()) > distance:\n",
    "            for key, value in closest.items():\n",
    "                if value == max(closest.values()):\n",
    "                    del_key = key\n",
    "                    continue\n",
    "            del closest[key]\n",
    "            closest[word] = distance\n",
    "    return closest\n",
    "\n",
    "            \n",
    "            \n",
    "back_wrds('amaretti', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Токенизация английского текста\n",
    "text = ' '.join(words)\n",
    "tok = word_tokenize(text)\n",
    "\n",
    "# Создание стеммера для английского языка\n",
    "snb_stemmer_en = SnowballStemmer('english')\n",
    "stemmed = [snb_stemmer_en.stem(t) for t in tok]\n",
    "\n",
    "# Пример нормализации слов с помощью библиотеки NLTK\n",
    "normalized = [word.lower() for word in tok]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amoretti</th>\n",
       "      <td>amoretti</td>\n",
       "      <td>amoretti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thickening</th>\n",
       "      <td>thicken</td>\n",
       "      <td>thickening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rose</th>\n",
       "      <td>rose</td>\n",
       "      <td>rose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kielbases</th>\n",
       "      <td>kielbas</td>\n",
       "      <td>kielbases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finsh</th>\n",
       "      <td>finsh</td>\n",
       "      <td>finsh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>done</th>\n",
       "      <td>done</td>\n",
       "      <td>done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feeds</th>\n",
       "      <td>feed</td>\n",
       "      <td>feeds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indgredients</th>\n",
       "      <td>indgredi</td>\n",
       "      <td>indgredients</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hulls</th>\n",
       "      <td>hull</td>\n",
       "      <td>hulls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shaking</th>\n",
       "      <td>shake</td>\n",
       "      <td>shaking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14926 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             stemmed_word normalized_word\n",
       "amoretti         amoretti        amoretti\n",
       "thickening        thicken      thickening\n",
       "rose                 rose            rose\n",
       "kielbases         kielbas       kielbases\n",
       "finsh               finsh           finsh\n",
       "...                   ...             ...\n",
       "done                 done            done\n",
       "feeds                feed           feeds\n",
       "indgredients     indgredi    indgredients\n",
       "hulls                hull           hulls\n",
       "shaking             shake         shaking\n",
       "\n",
       "[14926 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'stemmed_word': stemmed, 'normalized_word': normalized}, index=words[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Артём\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля стоп-слов: 47.08%\n",
      "Топ-10 слов до удаления стоп-слов:\n",
      "the: 40413\n",
      "a: 35131\n",
      "and: 30585\n",
      "i: 27945\n",
      "this: 27181\n",
      "to: 23598\n",
      "it: 23300\n",
      "is: 20306\n",
      "of: 18405\n",
      "for: 16023\n",
      "Топ-10 слов после удаления стоп-слов:\n",
      "recipe: 15198\n",
      "make: 6438\n",
      "time: 5287\n",
      "use: 4652\n",
      "great: 4522\n",
      "like: 4276\n",
      "easy: 4263\n",
      "one: 4018\n",
      "good: 3887\n",
      "made: 3874\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "recipes = pd.read_csv('data/preprocessed_descriptions.csv')\n",
    "recipes.columns = ['name', 'preprocessed_descriptions']\n",
    "\n",
    "# Загрузка стоп-слов\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Функция для удаления стоп-слов из текста\n",
    "def remove_stopwords(text, stop_words):\n",
    "    words = re.findall(r'\\b\\w+\\b', str(text).lower())\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "# Создание списка всех слов до и после удаления стоп-слов\n",
    "all_words_before = []\n",
    "all_words_after = []\n",
    "\n",
    "for description in recipes['preprocessed_descriptions']:\n",
    "    words_before = re.findall(r'\\b\\w+\\b', str(description).lower())\n",
    "    words_after = remove_stopwords(description, stop_words)\n",
    "    all_words_before.extend(words_before)\n",
    "    all_words_after.extend(words_after)\n",
    "\n",
    "# Подсчет общего количества слов и стоп-слов\n",
    "total_words = len(all_words_before)\n",
    "stop_words_count = total_words - len(all_words_after)\n",
    "\n",
    "# Доля стоп-слов\n",
    "stop_words_ratio = stop_words_count / total_words\n",
    "print(f'Доля стоп-слов: {stop_words_ratio:.2%}')\n",
    "\n",
    "# Подсчет частоты слов\n",
    "counter_before = Counter(all_words_before)\n",
    "counter_after = Counter(all_words_after)\n",
    "\n",
    "# Топ-10 слов до удаления стоп-слов\n",
    "top_10_before = counter_before.most_common(10)\n",
    "print(\"Топ-10 слов до удаления стоп-слов:\")\n",
    "for word, freq in top_10_before:\n",
    "    print(f'{word}: {freq}')\n",
    "\n",
    "# Топ-10 слов после удаления стоп-слов\n",
    "top_10_after = counter_after.most_common(10)\n",
    "print(\"Топ-10 слов после удаления стоп-слов:\")\n",
    "for word, freq in top_10_after:\n",
    "    print(f'{word}: {freq}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.20414271\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3048218  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.24592831 0.         0.\n",
      "  0.         0.         0.         0.         0.3048218  0.\n",
      "  0.         0.         0.17173129 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3048218  0.         0.         0.         0.\n",
      "  0.         0.         0.3048218  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.3048218  0.20414271\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3048218  0.         0.         0.         0.3048218  0.20414271\n",
      "  0.         0.         0.         0.20414271 0.3048218  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.20915997 0.         0.         0.16874894 0.\n",
      "  0.16874894 0.         0.         0.         0.         0.20915997\n",
      "  0.20915997 0.         0.         0.         0.         0.16874894\n",
      "  0.         0.         0.20915997 0.         0.         0.\n",
      "  0.         0.         0.20915997 0.         0.         0.\n",
      "  0.         0.         0.         0.20915997 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20915997 0.         0.20915997 0.         0.20915997\n",
      "  0.20915997 0.         0.         0.         0.         0.\n",
      "  0.20915997 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.20915997 0.\n",
      "  0.20915997 0.         0.         0.20915997 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.16874894\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.20915997 0.20915997 0.         0.         0.         0.16874894\n",
      "  0.         0.20915997 0.         0.         0.         0.\n",
      "  0.         0.         0.33749789 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.40933049\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.23060966 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.40933049 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.40933049 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.33024526 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.40933049 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.40933049]\n",
      " [0.         0.         0.         0.14299824 0.11537008 0.09576759\n",
      "  0.         0.28599648 0.         0.         0.14299824 0.\n",
      "  0.         0.         0.         0.         0.14299824 0.11537008\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14299824 0.         0.         0.14299824 0.         0.\n",
      "  0.14299824 0.         0.08056271 0.         0.         0.14299824\n",
      "  0.14299824 0.         0.14299824 0.14299824 0.         0.14299824\n",
      "  0.11537008 0.         0.14299824 0.14299824 0.         0.14299824\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14299824 0.         0.         0.11537008 0.14299824\n",
      "  0.         0.         0.14299824 0.14299824 0.         0.\n",
      "  0.14299824 0.         0.14299824 0.14299824 0.         0.14299824\n",
      "  0.         0.14299824 0.14299824 0.         0.         0.28730277\n",
      "  0.         0.14299824 0.         0.         0.14299824 0.\n",
      "  0.         0.         0.         0.         0.         0.09576759\n",
      "  0.         0.         0.14299824 0.19153518 0.         0.23074016\n",
      "  0.14299824 0.         0.14299824 0.         0.         0.\n",
      "  0.14299824 0.14299824 0.         0.14299824 0.11537008 0.        ]\n",
      " [0.13973637 0.         0.13973637 0.         0.         0.09358308\n",
      "  0.11273842 0.         0.13973637 0.13973637 0.         0.\n",
      "  0.         0.         0.13973637 0.13973637 0.         0.\n",
      "  0.13973637 0.13973637 0.         0.11273842 0.13973637 0.\n",
      "  0.         0.13973637 0.         0.         0.         0.27947274\n",
      "  0.         0.13973637 0.15745007 0.         0.13973637 0.\n",
      "  0.         0.13973637 0.         0.         0.         0.\n",
      "  0.22547685 0.         0.         0.         0.13973637 0.\n",
      "  0.13973637 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13973637 0.13973637 0.11273842 0.\n",
      "  0.         0.11273842 0.         0.         0.13973637 0.13973637\n",
      "  0.         0.13973637 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.18716615\n",
      "  0.13973637 0.         0.27947274 0.13973637 0.         0.11273842\n",
      "  0.         0.13973637 0.13973637 0.         0.         0.18716615\n",
      "  0.         0.         0.         0.18716615 0.         0.\n",
      "  0.         0.         0.         0.13973637 0.13973637 0.13973637\n",
      "  0.         0.         0.11273842 0.         0.22547685 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "recps = recipes.sample(5)\n",
    "descriptions = recps.preprocessed_descriptions\n",
    "titles = recps.name\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Преобразуем описания в числовые векторы\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(descriptions)\n",
    "\n",
    "# Выводим результат\n",
    "tfidf_vectors_array = tfidf_vectors.toarray()\n",
    "print(tfidf_vectors_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0|  1.4142135623730954|  1.4142135623730947|   1.414213562373095|   1.414213562373095|\n",
      "  1.4142135623730954|                   0|  1.2943304913343476|  1.3725568812139899|  1.4142135623730954|\n",
      "  1.4142135623730947|  1.2943304913343476|                   0|   1.414213562373095|   1.339217064165524|\n",
      "   1.414213562373095|  1.3725568812139899|   1.414213562373095|                   0|   1.414213562373095|\n",
      "   1.414213562373095|  1.4142135623730954|   1.339217064165524|   1.414213562373095|                   0|\n"
     ]
    }
   ],
   "source": [
    "def get_distance(array):\n",
    "    \"\"\"\n",
    "    Функция считает векторное расстояние между точками в любом количестве измерений для любого количества точек\n",
    "    \n",
    "    Input: Принимает матрицу из координат точек\n",
    "    Output: Возвращает матрицу размера NxN (N - количество точек) с расстояниями\n",
    "    \"\"\"\n",
    "    for i in range(1, len(array)):\n",
    "        if len(array[0]) != len(array[i]):\n",
    "            raise ValueError\n",
    "    shape = (len(array), len(array[0]))\n",
    "    result = [[0 for _ in range(shape[0])] for _ in range(shape[0])]\n",
    "    for j in range(shape[0] - 1):\n",
    "        for k in range(j + 1, shape[0]):\n",
    "            cnt = 0\n",
    "            for i in range(shape[1]):\n",
    "                cnt += (array[j][i] - array[k][i])**2\n",
    "            cnt = cnt**0.5\n",
    "            result[j][k] = cnt\n",
    "            result[k][j] = cnt\n",
    "    return result\n",
    "            \n",
    "            \n",
    "res = get_distance(tfidf_vectors_array)\n",
    "for i in res:\n",
    "    for j in i:\n",
    "        print(f\"{j:>20}\", end='|')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>sourdough jack bread</th>\n",
       "      <th>extra creamy mashed potatoes</th>\n",
       "      <th>sunday chicken stew</th>\n",
       "      <th>flaky deli slices</th>\n",
       "      <th>quick chicken  rice   veggie soup</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sourdough jack bread</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960397</td>\n",
       "      <td>0.849313</td>\n",
       "      <td>0.811505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra creamy mashed potatoes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922126</td>\n",
       "      <td>0.923902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunday chicken stew</th>\n",
       "      <td>0.960397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.981421</td>\n",
       "      <td>0.926459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flaky deli slices</th>\n",
       "      <td>0.849313</td>\n",
       "      <td>0.922126</td>\n",
       "      <td>0.981421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.805773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quick chicken  rice   veggie soup</th>\n",
       "      <td>0.811505</td>\n",
       "      <td>0.923902</td>\n",
       "      <td>0.926459</td>\n",
       "      <td>0.805773</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name                               sourdough jack bread  \\\n",
       "name                                                      \n",
       "sourdough jack bread                           0.000000   \n",
       "extra creamy mashed potatoes                   1.000000   \n",
       "sunday chicken stew                            0.960397   \n",
       "flaky deli slices                              0.849313   \n",
       "quick chicken  rice   veggie soup              0.811505   \n",
       "\n",
       "name                               extra creamy mashed potatoes  \\\n",
       "name                                                              \n",
       "sourdough jack bread                                   1.000000   \n",
       "extra creamy mashed potatoes                           0.000000   \n",
       "sunday chicken stew                                    1.000000   \n",
       "flaky deli slices                                      0.922126   \n",
       "quick chicken  rice   veggie soup                      0.923902   \n",
       "\n",
       "name                               sunday chicken stew  flaky deli slices  \\\n",
       "name                                                                        \n",
       "sourdough jack bread                          0.960397           0.849313   \n",
       "extra creamy mashed potatoes                  1.000000           0.922126   \n",
       "sunday chicken stew                           0.000000           0.981421   \n",
       "flaky deli slices                             0.981421           0.000000   \n",
       "quick chicken  rice   veggie soup             0.926459           0.805773   \n",
       "\n",
       "name                               quick chicken  rice   veggie soup  \n",
       "name                                                                  \n",
       "sourdough jack bread                                        0.811505  \n",
       "extra creamy mashed potatoes                                0.923902  \n",
       "sunday chicken stew                                         0.926459  \n",
       "flaky deli slices                                           0.805773  \n",
       "quick chicken  rice   veggie soup                           0.000000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(descriptions).toarray()\n",
    "\n",
    "# Вычисляем косинусное расстояние между каждой парой рецептов\n",
    "distance_matrix = pd.DataFrame(\n",
    "    [[cosine(tfidf_vectors[i], tfidf_vectors[j]) for j in range(len(titles))] for i in range(len(titles))],\n",
    "    index=titles,\n",
    "    columns=titles\n",
    ")\n",
    "\n",
    "# Выводим таблицу расстояний\n",
    "distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Похожими рецептами будут те, которые используют похожие или одиннаковые игридиенты и(или) готовятся одними и те ми же способами (перемешать, запечь, порезать и т.п.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
